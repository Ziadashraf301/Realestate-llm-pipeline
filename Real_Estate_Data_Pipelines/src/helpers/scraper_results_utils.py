import json
import os
import boto3

def scraper_report(results, logger):
    """Print detailed summary"""
    if not results:
        logger.warning("âŒ No data scraped")
        return
    
    logger.info("ğŸ“Š SCRAPING SUMMARY")
    logger.info(f"Total listings: {len(results)}")
    
    # Property types
    types = {}
    for listing in results:
        ptype = listing.get('property_type', 'unknown')
        types[ptype] = types.get(ptype, 0) + 1
    
    logger.info("\nğŸ“‹ By Property Type:")
    for ptype, count in sorted(types.items(), key=lambda x: x[1], reverse=True):
        logger.info(f"  â€¢ {ptype}: {count}")
    
    # Price statistics
    prices = [l['price_egp'] for l in results if l.get('price_egp')]
    if prices:
        logger.info("\nğŸ’° Price Statistics (EGP):")
        logger.info(f"  â€¢ Min: {min(prices):,.0f}")
        logger.info(f"  â€¢ Max: {max(prices):,.0f}")
        logger.info(f"  â€¢ Avg: {sum(prices)/len(prices):,.0f}")
    
    # Data completeness
    fields = ['bedrooms', 'bathrooms', 'area_sqm', 'description', 'images']
    logger.info("\nğŸ“ˆ Data Completeness:")
    for field in fields:
        count = sum(1 for l in results if l.get(field))
        percentage = (count / len(results)) * 100
        logger.info(f"  â€¢ {field}: {count}/{len(results)} ({percentage:.1f}%)")
    
    # Sample listings
    logger.info("ğŸ“‹ SAMPLE LISTINGS (first 3)")
    
    for i, listing in enumerate(results[:3], 1):
        logger.info(f"{i}. {listing['title'][:70]}")
        logger.info(f"ğŸ’° Price: {listing.get('price_text', 'N/A')}")
        logger.info(f"ğŸ“ Location: {listing['location'][:50]}")
        logger.info(f"ğŸ  Type: {listing['property_type']}")
        if listing.get('bedrooms'):
            logger.info(f"ğŸ›ï¸  {listing.get('bedrooms')} beds | ğŸš¿ {listing.get('bathrooms')} baths | ğŸ“ {listing.get('area_sqm')} mÂ²")
        logger.info(f"ğŸ”— {listing['url'][:70]}...")
        if listing.get('images'):
            logger.info(f"ğŸ“¸ Images: {len(listing['images'])}")
        logger.info("")


def save_to_json(filename, results, logger):
    """Save results to JSON (append mode)""" 
    # Load existing data if file exists
    existing_data = []
    if os.path.exists(filename):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except json.JSONDecodeError:
            logger.warning(f"Could not read existing {filename}, starting fresh")
        
    # Merge new results with existing (avoid duplicates by property_id)
    existing_ids = {item.get('property_id') for item in existing_data}
    new_items = [item for item in results if item.get('property_id') not in existing_ids]
        
    combined_data = existing_data + new_items
        
    # Save combined data
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(combined_data, f, indent=2, ensure_ascii=False)
        
    logger.info(f"âœ… Added {len(new_items)} new properties to {filename} (Total: {len(combined_data)})")


def upload_to_s3(local_file_path, bucket_name, s3_key, logger):
    """Upload a file to an S3 bucket"""
    s3 = boto3.client("s3")

    try:
        s3.upload_file(local_file_path, bucket_name, s3_key)
        logger.info(f"ğŸ“¤ Uploaded to S3: s3://{bucket_name}/{s3_key}")
    except Exception as e:
        logger.error(f"âŒ S3 upload failed: {e}")
        raise